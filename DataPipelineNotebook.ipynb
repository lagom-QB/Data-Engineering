{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, f1_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "file_path = 'airflow/dags/assets/matches-checkpoint.csv'\n",
    "spanish_squads = ['Sevilla', 'Sporting Huelva', 'Athletic Club', 'Levante Planas',\n",
    "                  'UDG Tenerife', 'Villarreal', 'Madrid CFF', 'Barcelona',\n",
    "                  'Atlético Madrid', 'Real Madrid', 'Alhama', 'Alavés',\n",
    "                  'Real Sociedad', 'Levante', 'Real Betis', 'Valencia']\n",
    "useless_columns= [ 'Home_id', 'Away_id', 'Match_id', 'League_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "matches = pd.read_csv(file_path)\n",
    "matches = matches.drop(columns=useless_columns)\n",
    "\n",
    "# Drop the rows in which the home or away team is not a spanish team\n",
    "matches = matches[matches['Home'].isin(spanish_squads) | matches['Away'].isin(spanish_squads)]\n",
    "\n",
    "display(matches.describe(), matches.sample(3), matches.info(), matches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA and preprocessing and handle data type conversions.\n",
    "matches['Time'] = matches['Time'].apply(lambda a: datetime.strptime(a, '%H:%M').time()) # Convert to timedelta\n",
    "matches['Date'] = pd.to_datetime(matches['Date']) # Convert to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of missing values in each column\n",
    "display(matches.isnull().sum())\n",
    "\n",
    "# Plot single variable scatterplots\n",
    "for column in matches.columns:\n",
    "    # if column type is object, skip it\n",
    "    if matches[column].dtype == 'object':\n",
    "        continue\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    plt.title(column)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    sns.scatterplot(x=matches[column].value_counts().index, y=matches[column].value_counts(), color='red', alpha=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\"\"\"# Plot the missing values in columns with missing values as a histogram\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.title('Count of missing values in columns')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Missing values')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(0,5)\n",
    "\n",
    "sns.barplot(x=matches.columns, y=matches.isnull().sum(), fill=None, linewidth=1)\n",
    "\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the statistical properties of the data, structure, features, etc.\n",
    "display(matches.sample(4))\n",
    "\n",
    "# Histogram of scores in seaborn\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(matches['ScoreHome'], kde=True, stat='count', bins=10)\n",
    "sns.histplot(matches['ScoreAway'], kde=True, stat='count', bins=10)\n",
    "\n",
    "plt.title('Score Distribution')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(['Home', 'Away'])\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 30)\n",
    "\n",
    "plt.show() \n",
    "\n",
    "# Histogram of Expected Goals in seaborn\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(matches['xGHome'], kde=True, stat='count', bins=10)\n",
    "sns.histplot(matches['xGAway'], kde=True, stat='count', bins=10)\n",
    "\n",
    "plt.title('Expected Goals Distribution')\n",
    "plt.xlabel('Expected Goals')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(['Home', 'Away'])\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 30)\n",
    "\n",
    "plt.show() # Expected goals are more normally distributed than actual goals\n",
    "\n",
    "# Barplot of Match days in seaborn\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=matches['Day'].value_counts().index, y=matches['Day'].value_counts().values)\n",
    "\n",
    "plt.title('Matchday Distribution')\n",
    "plt.xlabel('Matchday')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinePlot of Scores over time in seaborn\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "sns.lineplot(markers=True, marker='o', x='Date', y='ScoreHome', data=matches, label='Home')\n",
    "sns.lineplot(markers=True, marker='+', x='Date', y='ScoreAway', data=matches, label='Away')\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "plt.title('Scores over time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Team')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of Expected Goals Home and Away wo show the distribution of the data\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "sns.boxplot(data=matches[['xGHome', 'xGAway']], notch=True, orient='h')\n",
    "\n",
    "plt.title('Expected Goals Home and Away')\n",
    "plt.xlabel('Expected Goals')\n",
    "plt.ylabel('Team')\n",
    "\n",
    "plt.show()\n",
    "# ------------------------------------------------- Same as above but with the kdeplot\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "sns.kdeplot(x=matches['ScoreHome'], shade=True)\n",
    "sns.kdeplot(x=matches['ScoreAway'], shade=True)\n",
    "\n",
    "plt.title('Score Distribution for Home and Away')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(['Home', 'Away'])\n",
    "plt.xlim(0, 5.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the distribution of scores change as the weeks go by?\n",
    "plt.figure(figsize=(10, 35))\n",
    "\n",
    "integer_columns = ['xGHome', 'ScoreHome', 'xGAway', 'ScoreAway']\n",
    "weeks = matches['Wk'].unique()\n",
    "num_weeks = len(weeks)\n",
    "num_cols = len(integer_columns) // 2\n",
    "\n",
    "for i, week in enumerate(weeks):\n",
    "    plt.subplot(num_weeks, num_cols, i*num_cols+1)\n",
    "    plt.ylim(0, 6)\n",
    "    plt.xlim(0, 8)\n",
    "    for col in integer_columns[:2]:\n",
    "        sns.histplot(matches[matches['Wk'] == week][col], stat='count', kde=True, label=col)\n",
    "    plt.title(f'Week {week}')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(num_weeks, num_cols, i*num_cols+2)\n",
    "    plt.ylim(0, 6)\n",
    "    plt.xlim(0, 8)\n",
    "    for col in integer_columns[2:]:\n",
    "        sns.histplot(matches[matches['Wk'] == week][col], stat='count', kde=True, label=col)\n",
    "    plt.title(f'Week {week}')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a correlation between the expected goals and the actual goals?\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for i, col in enumerate(['Home', 'Away']):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "\n",
    "    plt.xlim(0, 8)\n",
    "    plt.ylim(0, 30)\n",
    "    \n",
    "    sns.histplot(x=f'Score{col}', data=matches,  kde=True, stat='count', bins=10)\n",
    "    sns.histplot(x=f'xG{col}', data=matches,  kde=True, stat='count', bins=10)\n",
    "    \n",
    "    plt.title(f'Score vs Expected Goals {col}')\n",
    "\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('')\n",
    "plt.legend(['Score', 'Expected Goals'])\n",
    "\n",
    "plt.show() \n",
    "\n",
    "# Plot the correlation matrix\n",
    "numeric_columns = matches.select_dtypes(include=np.number).columns\n",
    "correlations = matches[numeric_columns].corr()\n",
    "columns = correlations.columns\n",
    "rows = correlations.index\n",
    "\n",
    "corresponding = []\n",
    "correlations_list = []\n",
    "\n",
    "for col in columns:\n",
    "    for row in rows:\n",
    "        corresponding.append(row+'_'+col)\n",
    "\n",
    "correlations = correlations.values.flatten()\n",
    "\n",
    "for idx, value in enumerate(corresponding):\n",
    "    correlations_list.append([value, correlations[idx]])   \n",
    "\n",
    "processed_labels = set()\n",
    "labels = []\n",
    "values = []\n",
    "\n",
    "for label, value in sorted(correlations_list, key=lambda x: x[1]):\n",
    "    reverse_label = '_'.join(label.split('_')[::-1])\n",
    "    \n",
    "    if label not in processed_labels and reverse_label not in processed_labels and label != reverse_label:\n",
    "        labels.append(label)\n",
    "        values.append(value)\n",
    "        processed_labels.add(label)\n",
    "\n",
    "sorted_labels, sorted_values = zip(*sorted(zip(labels, values), key=lambda x: x[1]))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,10))\n",
    "\n",
    "norm=TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1)\n",
    "sns.barplot(y=sorted_labels, x=sorted_values, palette=sns.color_palette('RdYlGn', len(sorted_labels)), order=sorted_labels)\n",
    "\n",
    "plt.xlabel('Correlation')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interaction terms: Multiplication of 2 features which have a joint effect on the target variable to create a new feature that captures this effect.\n",
    "interaction_terms = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "interaction_var   = interaction_terms.fit_transform(matches[['xGHome', 'xGAway']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Categorical Features\n",
    "categorical_columns = matches.select_dtypes(include='object').columns #['Day', 'Time', 'Home', 'Score', 'Away']\n",
    "useful_categorical  = categorical_columns.drop('Score')\n",
    "\n",
    "matches['Numeric_Day'] = matches['Day'].apply(lambda x: 2 if x == 'Tue' else 3 if x == 'Wed' else 4 if x == 'Thu' else 6 if x == 'Sat' else 7) # Encode the Day column\n",
    "display(matches['Time'].value_counts()) # I was going to ignore the Time column\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "matches['Numeric_Home'] = encoder.fit_transform(matches['Home'])\n",
    "matches['Numeric_Away'] = encoder.transform(matches['Away']) # Use the same encoder as the Home column\"\"\"\n",
    "\n",
    "encoder_time = OrdinalEncoder()\n",
    "matches['Numeric_Time'] = encoder_time.fit_transform(matches['Time'].values.reshape(-1, 1)) # Ignore the first column to avoid the dummy variable trap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the interaction terms to the matches dataframe\n",
    "matches_encoded = pd.concat([matches, pd.DataFrame(interaction_var, columns=['i_t1', 'i_t2', 'i_t3'])], axis=1)\n",
    "\n",
    "# display(matches_encoded.sample(3), matches_encoded.info(), matches_encoded.shape)\n",
    "\n",
    "# Drop the categorical columns\n",
    "matches_encoded = matches_encoded.select_dtypes(include=['int64', 'float64'])\n",
    "display(matches_encoded.sample(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What features have the highest correlation with the target variable?\n",
    "correlations_home = matches_encoded.corr().sort_values(['ScoreHome']).ScoreHome\n",
    "correlations_away = matches_encoded.corr().sort_values(['ScoreAway']).ScoreAway\n",
    "\n",
    "# display(correlations_home, correlations_away)\n",
    "\n",
    "norm=TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1)\n",
    "\n",
    "plt.figure(figsize=(6,9))\n",
    "sns.barplot(y=correlations_home[:-1].keys(), x=correlations_home[:-1].values, palette=sns.color_palette('RdYlGn', len(correlations_home)))\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylabel('Features')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,9))\n",
    "sns.barplot(y=correlations_away[:-1].keys(), x=correlations_away[:-1].values, palette=sns.color_palette('RdYlGn', len(correlations_away)))\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = matches_encoded.drop(columns=['ScoreHome', 'ScoreAway'])\n",
    "y = matches_encoded[['ScoreHome']].squeeze() # 'ScoreAway'\n",
    "\n",
    "display(X.sample(3), y.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(matches_encoded.sample(3))\n",
    "# Split the data into train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  train_size=.6, \n",
    "                                                  random_state=42) \n",
    "                                    # Next time, try to predict the away score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    train_size=.5, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = pd.DataFrame(columns=['Model','Training MSE', 'Validation MSE', 'Training R2', 'Validation R2'])\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': AdaBoostRegressor(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.5, 1]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': KernelRidge(),\n",
    "        'params':{\n",
    "            'alpha':[0.1, 0.5, 1, 5, 10],\n",
    "            'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'degree':[2, 3, 4, 5],\n",
    "            'coef0':[0.1, 0.5, 1, 5, 10]\n",
    "        }\n",
    "    },{\n",
    "        'model': GradientBoostingRegressor(),\n",
    "        'params':{\n",
    "            'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "            'max_depth': [5, 10, 15, 20],\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [5, 2, 4],\n",
    "            'loss': ['ls', 'lad', 'huber', 'quantile']\n",
    "        }\n",
    "    },{\n",
    "        'model': LGBMRegressor(),\n",
    "        'params':{\n",
    "            'objective':['regression'],\n",
    "            'num_leaves':[5, 10, 15, 20, 25, 30],\n",
    "            'learning_rate':[0.01, 0.05, 0.1, 0.5, 1],\n",
    "            'n_estimators':[100, 200, 300, 400, 500],\n",
    "            'max_bin':[10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "            'bagging_fraction':[0.5, 0.75, 1],\n",
    "            'bagging_freq':[5, 10, 15, 20],\n",
    "            'feature_fraction':[0.5, 0.75, 1],\n",
    "            'feature_fraction_seed':[5, 10, 15, 20],\n",
    "            'bagging_seed':[5, 10, 15, 20],\n",
    "            'min_data_in_leaf':[5, 10, 15, 20],\n",
    "            'min_sum_hessian_in_leaf':[5, 10, 15, 20]\n",
    "        }\n",
    "    },{\n",
    "        'model':SVR(),\n",
    "        'params': {\n",
    "            'C': [0.1, 0.5, 1, 5, 10],\n",
    "            'epsilon': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    }\n",
    "},{\n",
    "        'model': XGBRegressor(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'colsample_bytree': [0.5, 0.75, 1],\n",
    "            'max_depth': [5, 10, 15, 20],\n",
    "            'reg_alpha': [0.1, 0.5, 1],\n",
    "            'reg_lambda': [0.1, 0.5, 1],\n",
    "            'subsample': [0.5, 0.75, 1],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "            'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "            'objective': ['reg:logistic', 'reg:squarederror']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'max_depth': [5, 10, 15, 20],\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [5, 2, 4],\n",
    "            'criterion': ['mse', 'mae']\n",
    "        }\n",
    "    }] \n",
    "def tune_hyperparameters(idx):\n",
    "    model = param_grid[idx]['model']\n",
    "    params = param_grid[idx]['params']\n",
    "\n",
    "    classifier = GridSearchCV(model,\n",
    "                              params,\n",
    "                              cv=5,\n",
    "                              return_train_score=True,\n",
    "                              verbose=0,\n",
    "                              n_jobs=-1)\n",
    "    # classifier.fit(X_train, y_train)\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 50\n",
    "\n",
    "\"\"\"\n",
    "TODO::\n",
    "    - Optimize this function so it runs faster and doesn't take up so much memory\n",
    "\"\"\"\n",
    "def plot_loss_fxn(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, n_iterations=n_iterations, idx= 0):\n",
    "    global model_eval\n",
    "    model = tune_hyperparameters(idx)\n",
    "\n",
    "    # if model.__class__.__name__ == 'SVR':\n",
    "    #     X_train = StandardScaler().fit_transform(X_train)\n",
    "    #     X_val = StandardScaler().fit_transform(X_val)\n",
    "    mse_train = []\n",
    "    mse_val   = []\n",
    "    r2_train  = []\n",
    "    r2_val    = []\n",
    "    y_train_pred = []\n",
    "\n",
    "    for epoch in range(n_iterations):\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        curr_mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        curr_mse_val   = mean_squared_error(y_val, y_val_pred)\n",
    "        \n",
    "        curr_r2_train  = r2_score(y_train, y_train_pred)\n",
    "        curr_r2_val    = r2_score(y_val, y_val_pred)\n",
    "        \n",
    "        mse_train.append(curr_mse_train)\n",
    "        mse_val.append(curr_mse_val)  \n",
    "        r2_train.append(curr_r2_train) \n",
    "        r2_val.append(curr_r2_val)   \n",
    "        \n",
    "        plt.figure(figsize=(14,6))\n",
    "        \n",
    "        plt.xlim(0, n_iterations)\n",
    "        plt.ylim(-1, 5)\n",
    "        \n",
    "        plt.plot(r2_val, linewidth=.8, label='Validation R2')\n",
    "        plt.plot(mse_val, linewidth=.8, label='Validation MSE')\n",
    "        plt.plot(r2_train, linewidth=.8, label='Training R2')\n",
    "        plt.plot(mse_train, linewidth=.8, label='Training MSE')\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.xlabel(f'mse train: {curr_mse_train:.4f} | mse val: {curr_mse_val:.4f} | r2 train: {curr_r2_train:.4f} | r2 val: {curr_r2_val:.4f}')\n",
    "        plt.title(f'Model: {model.__class__.__name__} | Best Score: {model.best_score_} | Best Params: {model.best_estimator_}\\n Epoch: {epoch+1}/{n_iterations}\\n Training R2: {curr_r2_train:.4f} | Validation R2: {curr_r2_val:.4f}\\n Training MSE: {curr_mse_train:.4f} | Validation MSE: {curr_mse_val:.4f}')\n",
    "        # plt.pause(1.2)\n",
    "        \n",
    "        plt.savefig(f'airflow/dags/assets/{model.best_estimator_.__class__.__name__}_loss_fxn.png', bbox_inches='tight', pad_inches=0.5, dpi=300, format='png')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(14,6))\n",
    "    \n",
    "    sns.scatterplot(x=y_train.index, y=y_train.values.flatten(), label='Actual')\n",
    "    plt.hlines(y=y_train_pred.flatten(), xmin=y_train.index.min(), xmax=y_train.index.max(), colors='red', label='Predicted')\n",
    "    sns.scatterplot(x=y_train.index, y=y_train_pred.flatten(), label='Predicted')\n",
    "    plt.hlines(y=y_train.values.flatten(), xmin=y_train.index.min(), xmax=y_train.index.max(), colors='red', label='Actual')\n",
    "    \n",
    "    plt.title(f'Model: {model.__class__.__name__}\\n Actual vs Predicted Scores')\n",
    "    # plt.xlabel(f'accuracy {accuracy_score(y_train, y_train_pred):.4f} | precision {precision_score(y_train, y_train_pred):.4f} | recall {recall_score(y_train, y_train_pred):.4f} | f1 {f1_score(y_train, y_train_pred):.4f}')\n",
    "    \n",
    "    plt.savefig(f'airflow/dags/assets/{model.best_estimator_.__class__.__name__}_actual_vs_predicted.png', bbox_inches='tight', pad_inches=0.5, dpi=300, format='png')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    new_row = {'Model': model.__class__.__name__, \n",
    "               'Training MSE': curr_mse_train, \n",
    "               'Validation MSE': curr_mse_val,\n",
    "               'Training R2': curr_r2_train,\n",
    "               'Validation R2': curr_r2_val}\n",
    "    model_eval = pd.concat([model_eval, \n",
    "                            pd.DataFrame([new_row])], \n",
    "                           ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the r2-score.\n",
    "The R2 score is a statistical measure that determines if the linear regression predictions approximate the actual data.\n",
    "- A value of 1 indicates that the regression predictions perfectly fit the data.\n",
    "- A value of 0 indicates that the regression predictions do not fit the data.\n",
    "- A value of -1 indicates that the regression predictions fit the data but in the opposite direction.\n",
    "- 0>R2>1 indicates the amount of variance in the target variable that is explained by the model.\n",
    "\n",
    "AdaBoostRegressor:\n",
    "    + The high r2 score shows that the model is a good fit for the training data.\n",
    "    + The r2 score of ~.25 shows the model is not a good fit for the validation data.\n",
    "\n",
    "XGBRegressor:\n",
    "    + The high r2 score shows that the model is a good fit for the training data.\n",
    "    + The r2 score of .33 shows the model is not a good fit for the validation data.\n",
    "    \n",
    "LGBMRegressor:\n",
    "    + The r2 score of 0 shows that the model is not a good fit for the training data.\n",
    "    + The -ve r2 score of -.01 shows the model is an opposite fit for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_fxn(idx=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_fxn(idx=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_fxn(idx=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_fxn(idx=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_fxn(idx=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airflow and SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the model and its parameters and metrics into an sqlite database using an airflow pipeline\n",
    "- Split the notebook into python file(s) # Documentation\n",
    "- How to run serve the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_airflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
