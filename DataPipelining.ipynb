{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# import sqlite3\n",
    "# from airflow import DAG\n",
    "# from airflow.utils.dates import days_ago\n",
    "# from airflow.operators.python_operator import PythonOperator\n",
    "\n",
    "import nbformat\n",
    "\n",
    "import warnings\n",
    "from typing import Optional, Tuple, Callable, Dict, Any, List, Union\n",
    "import fire\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create a requirements.txt file with the necessary packages\n",
    "# !pip freeze > airflow/dags/requirements.txt\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "from fastapi import FastAPI\n",
    "\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.load_data import load_data_from_source\n",
    "from app.transform_data import transform_data_into_features_and_targets\n",
    "from app.baseline_model import train_baseline\n",
    "\n",
    "from app.train_models import train_model, save_best_model, training_process\n",
    "\n",
    "from app.model_prediction import predict_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- VARIABLES ----\n",
    "explanable_cols = ['Player','Nation','Pos','Squad','Age','Born','Starts','Min','Gls','Total_Att','Blocks_Blocks','Blocks_Sh','Blocks_Pass','Clr','Err','Touches_Touches','Touches_DefPen','Dribbles_Succ','Dribbles_Att','Dribbles_Mis','AerialDuels_Won','AerialDuels_Lost']\n",
    "file_loc       = 'airflow/dags/assets/matches-checkpoint.csv'\n",
    "spanish_squads = ['Sevilla', 'Sporting Huelva', 'Athletic Club', 'Levante Planas',\n",
    "                  'UDG Tenerife', 'Villarreal', 'Madrid CFF', 'Barcelona',\n",
    "                  'Atlético Madrid', 'Real Madrid', 'Alhama', 'Alavés',\n",
    "                  'Real Sociedad', 'Levante', 'Real Betis', 'Valencia']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Wk         306 non-null    int64  \n",
      " 1   Day        306 non-null    object \n",
      " 2   Date       306 non-null    object \n",
      " 3   Time       306 non-null    object \n",
      " 4   Home       306 non-null    object \n",
      " 5   xGHome     305 non-null    float64\n",
      " 6   Score      306 non-null    object \n",
      " 7   xGAway     305 non-null    float64\n",
      " 8   Away       306 non-null    object \n",
      " 9   Home_id    306 non-null    object \n",
      " 10  Away_id    306 non-null    object \n",
      " 11  Match_id   306 non-null    object \n",
      " 12  League_id  306 non-null    int64  \n",
      " 13  xPHome     306 non-null    float64\n",
      " 14  xPAway     306 non-null    float64\n",
      " 15  ScoreHome  306 non-null    int64  \n",
      " 16  ScoreAway  306 non-null    int64  \n",
      "dtypes: float64(4), int64(4), object(9)\n",
      "memory usage: 40.8+ KB\n",
      "(306, 17) None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wk</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Home</th>\n",
       "      <th>xGHome</th>\n",
       "      <th>Score</th>\n",
       "      <th>xGAway</th>\n",
       "      <th>Away</th>\n",
       "      <th>Home_id</th>\n",
       "      <th>Away_id</th>\n",
       "      <th>Match_id</th>\n",
       "      <th>League_id</th>\n",
       "      <th>xPHome</th>\n",
       "      <th>xPAway</th>\n",
       "      <th>ScoreHome</th>\n",
       "      <th>ScoreAway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2022-09-17</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2–0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>UDG Tenerife</td>\n",
       "      <td>15f49df1</td>\n",
       "      <td>4c088abe</td>\n",
       "      <td>4df3a732</td>\n",
       "      <td>230</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2022-09-17</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Alavés</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1–2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Madrid CFF</td>\n",
       "      <td>aa11fb42</td>\n",
       "      <td>89818574</td>\n",
       "      <td>87c755cd</td>\n",
       "      <td>230</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2022-09-17</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Real Sociedad</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2–0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Villarreal</td>\n",
       "      <td>c21f25d3</td>\n",
       "      <td>7a7bef84</td>\n",
       "      <td>abfde9d9</td>\n",
       "      <td>230</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2022-09-17</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2–0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>54582b93</td>\n",
       "      <td>f96ff499</td>\n",
       "      <td>d0329f46</td>\n",
       "      <td>230</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2022-09-17</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Sevilla</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1–3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Atlético Madrid</td>\n",
       "      <td>215d9026</td>\n",
       "      <td>b56c2667</td>\n",
       "      <td>f4452586</td>\n",
       "      <td>230</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wk  Day        Date   Time           Home  xGHome Score  xGAway  \\\n",
       "0   2  Sat  2022-09-17  12:00      Barcelona     1.9   2–0     0.4   \n",
       "1   2  Sat  2022-09-17  12:00         Alavés     1.1   1–2     1.2   \n",
       "2   2  Sat  2022-09-17  16:00  Real Sociedad     0.7   2–0     0.3   \n",
       "3   2  Sat  2022-09-17  16:00    Real Madrid     1.6   2–0     0.8   \n",
       "4   2  Sat  2022-09-17  18:00        Sevilla     1.1   1–3     1.4   \n",
       "\n",
       "              Away   Home_id   Away_id  Match_id  League_id  xPHome  xPAway  \\\n",
       "0     UDG Tenerife  15f49df1  4c088abe  4df3a732        230    2.40    0.40   \n",
       "1       Madrid CFF  aa11fb42  89818574  87c755cd        230    1.29    1.43   \n",
       "2       Villarreal  c21f25d3  7a7bef84  abfde9d9        230    1.68    0.87   \n",
       "3         Valencia  54582b93  f96ff499  d0329f46        230    1.94    0.80   \n",
       "4  Atlético Madrid  215d9026  b56c2667  f4452586        230    1.15    1.58   \n",
       "\n",
       "   ScoreHome  ScoreAway  \n",
       "0          2          0  \n",
       "1          1          2  \n",
       "2          2          0  \n",
       "3          2          0  \n",
       "4          1          3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_data_from_source()\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data\n",
    "\n",
    "Transform the loaded data into _features_ and _target_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_home, target_home = transform_data_into_features_and_targets(df=data, score='ScoreHome')\n",
    "features_away, target_away = transform_data_into_features_and_targets(df=data, score='ScoreAway')\n",
    "\n",
    "# Remember that features_home and features_away are the same, so we can use either one\n",
    "# However, target_home and target_away are different, so we need to concatenate them in order to have the full target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "Establish a baseline performance against which to compare future better models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline error: 1.1404786680541104\n",
      "Baseline error: 1.2851196670135276\n"
     ]
    }
   ],
   "source": [
    "train_baseline(features_home, target_home)\n",
    "train_baseline(features_away, target_away)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                model  \\\n",
      "0                       Ridge(alpha=1, solver='lsqr')   \n",
      "1           LinearRegression(n_jobs=1, positive=True)   \n",
      "2   KernelRidge(alpha=10, degree=1, gamma=1, kerne...   \n",
      "3   SGDRegressor(alpha=0.1, learning_rate='optimal...   \n",
      "4   (DecisionTreeRegressor(max_depth=2, max_featur...   \n",
      "5   XGBRegressor(base_score=None, booster=None, ca...   \n",
      "6   ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
      "7   (DecisionTreeRegressor(max_depth=3, random_sta...   \n",
      "8                  DecisionTreeRegressor(max_depth=2)   \n",
      "9                 KNeighborsRegressor(n_neighbors=10)   \n",
      "10                  ElasticNet(alpha=1, l1_ratio=0.1)   \n",
      "11                                     Lasso(alpha=1)   \n",
      "\n",
      "                                               params       mae  \\\n",
      "0   {'alpha': 1, 'fit_intercept': True, 'solver': ...  0.827189   \n",
      "1   {'fit_intercept': True, 'n_jobs': 1, 'positive...  0.832842   \n",
      "2   {'alpha': 10, 'degree': 1, 'gamma': 1, 'kernel...  0.838041   \n",
      "3   {'alpha': 0.1, 'fit_intercept': True, 'learnin...  0.862552   \n",
      "4               {'max_depth': 2, 'n_estimators': 150}  0.882906   \n",
      "5                {'max_depth': 2, 'n_estimators': 50}  0.886967   \n",
      "6                {'max_depth': 2, 'n_estimators': 50}  0.891445   \n",
      "7          {'learning_rate': 0.1, 'n_estimators': 50}  0.911734   \n",
      "8                                    {'max_depth': 2}  0.923438   \n",
      "9                                 {'n_neighbors': 10}  0.975806   \n",
      "10  {'alpha': 1, 'fit_intercept': True, 'l1_ratio'...  1.055774   \n",
      "11                {'alpha': 1, 'fit_intercept': True}  1.330403   \n",
      "\n",
      "                     time  \n",
      "0  0 days 00:00:01.515892  \n",
      "1  0 days 00:00:00.636021  \n",
      "2  0 days 00:00:24.589754  \n",
      "3  0 days 00:00:29.817237  \n",
      "4  0 days 00:01:17.597466  \n",
      "5  0 days 00:00:48.528156  \n",
      "6  0 days 00:00:44.486262  \n",
      "7  0 days 00:00:53.434618  \n",
      "8  0 days 00:00:00.250397  \n",
      "9  0 days 00:00:00.215951  \n",
      "10 0 days 00:00:01.215019  \n",
      "11 0 days 00:00:00.312553  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge(alpha=1, solver='lsqr')</td>\n",
       "      <td>{'alpha': 1, 'fit_intercept': True, 'solver': ...</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0 days 00:00:01.515892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression(n_jobs=1, positive=True)</td>\n",
       "      <td>{'fit_intercept': True, 'n_jobs': 1, 'positive...</td>\n",
       "      <td>0.832842</td>\n",
       "      <td>0 days 00:00:00.636021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KernelRidge(alpha=10, degree=1, gamma=1, kerne...</td>\n",
       "      <td>{'alpha': 10, 'degree': 1, 'gamma': 1, 'kernel...</td>\n",
       "      <td>0.838041</td>\n",
       "      <td>0 days 00:00:24.589754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGDRegressor(alpha=0.1, learning_rate='optimal...</td>\n",
       "      <td>{'alpha': 0.1, 'fit_intercept': True, 'learnin...</td>\n",
       "      <td>0.862552</td>\n",
       "      <td>0 days 00:00:29.817237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(DecisionTreeRegressor(max_depth=2, max_featur...</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 150}</td>\n",
       "      <td>0.882906</td>\n",
       "      <td>0 days 00:01:17.597466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, ca...</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 50}</td>\n",
       "      <td>0.886967</td>\n",
       "      <td>0 days 00:00:48.528156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 50}</td>\n",
       "      <td>0.891445</td>\n",
       "      <td>0 days 00:00:44.486262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(DecisionTreeRegressor(max_depth=3, random_sta...</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 50}</td>\n",
       "      <td>0.911734</td>\n",
       "      <td>0 days 00:00:53.434618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTreeRegressor(max_depth=2)</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>0.923438</td>\n",
       "      <td>0 days 00:00:00.250397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.975806</td>\n",
       "      <td>0 days 00:00:00.215951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ElasticNet(alpha=1, l1_ratio=0.1)</td>\n",
       "      <td>{'alpha': 1, 'fit_intercept': True, 'l1_ratio'...</td>\n",
       "      <td>1.055774</td>\n",
       "      <td>0 days 00:00:01.215019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>{'alpha': 1, 'fit_intercept': True}</td>\n",
       "      <td>1.330403</td>\n",
       "      <td>0 days 00:00:00.312553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  \\\n",
       "0                       Ridge(alpha=1, solver='lsqr')   \n",
       "1           LinearRegression(n_jobs=1, positive=True)   \n",
       "2   KernelRidge(alpha=10, degree=1, gamma=1, kerne...   \n",
       "3   SGDRegressor(alpha=0.1, learning_rate='optimal...   \n",
       "4   (DecisionTreeRegressor(max_depth=2, max_featur...   \n",
       "5   XGBRegressor(base_score=None, booster=None, ca...   \n",
       "6   ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "7   (DecisionTreeRegressor(max_depth=3, random_sta...   \n",
       "8                  DecisionTreeRegressor(max_depth=2)   \n",
       "9                 KNeighborsRegressor(n_neighbors=10)   \n",
       "10                  ElasticNet(alpha=1, l1_ratio=0.1)   \n",
       "11                                     Lasso(alpha=1)   \n",
       "\n",
       "                                               params       mae  \\\n",
       "0   {'alpha': 1, 'fit_intercept': True, 'solver': ...  0.827189   \n",
       "1   {'fit_intercept': True, 'n_jobs': 1, 'positive...  0.832842   \n",
       "2   {'alpha': 10, 'degree': 1, 'gamma': 1, 'kernel...  0.838041   \n",
       "3   {'alpha': 0.1, 'fit_intercept': True, 'learnin...  0.862552   \n",
       "4               {'max_depth': 2, 'n_estimators': 150}  0.882906   \n",
       "5                {'max_depth': 2, 'n_estimators': 50}  0.886967   \n",
       "6                {'max_depth': 2, 'n_estimators': 50}  0.891445   \n",
       "7          {'learning_rate': 0.1, 'n_estimators': 50}  0.911734   \n",
       "8                                    {'max_depth': 2}  0.923438   \n",
       "9                                 {'n_neighbors': 10}  0.975806   \n",
       "10  {'alpha': 1, 'fit_intercept': True, 'l1_ratio'...  1.055774   \n",
       "11                {'alpha': 1, 'fit_intercept': True}  1.330403   \n",
       "\n",
       "                     time  \n",
       "0  0 days 00:00:01.515892  \n",
       "1  0 days 00:00:00.636021  \n",
       "2  0 days 00:00:24.589754  \n",
       "3  0 days 00:00:29.817237  \n",
       "4  0 days 00:01:17.597466  \n",
       "5  0 days 00:00:48.528156  \n",
       "6  0 days 00:00:44.486262  \n",
       "7  0 days 00:00:53.434618  \n",
       "8  0 days 00:00:00.250397  \n",
       "9  0 days 00:00:00.215951  \n",
       "10 0 days 00:00:01.215019  \n",
       "11 0 days 00:00:00.312553  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rankings_home = {}\n",
    "training_process(rankings_home, features_home, target_home)\n",
    "# train_model(rankings_home,'LinearRegression', features_home, target_home)\n",
    "# train_model(rankings_home,'AdaBoostRegressor', features_home, target_home)\n",
    "# train_model(rankings_home,'RandomForestRegressor', features_home, target_home)\n",
    "# train_model(rankings_home,'XGBRegressor', features_home, target_home)\n",
    "# # train_model(rankings_home,'DecisionTreeRegressor', features_home, target_home)\n",
    "# # train_model(rankings_home,'KNeighborsRegressor', features_home, target_home)\n",
    "# # train_model(rankings_home,'GradientBoostingRegressor', features_home, target_home)\n",
    "# # train_model(rankings_home,'Ridge', features_home, target_home)\n",
    "# # train_model(rankings_home,'Lasso', features_home, target_home)\n",
    "# # train_model(rankings_home,'ElasticNet', features_home, target_home)\n",
    "# # train_model(rankings_home,'SGDRegressor', features_home, target_home)\n",
    "# # train_model(rankings_home,'KernelRidge', features_home, target_home)\n",
    "\n",
    "# print(sorted(rankings_home.items(), key=lambda x: x[1]['mae']))\n",
    "\n",
    "# Save models and their info\n",
    "save_best_model('home',rankings_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ridge', {'model': Ridge(alpha=1, solver='lsqr'), 'params': {'alpha': 1, 'fit_intercept': True, 'solver': 'lsqr'}, 'mae': 0.8271892857909143, 'time': datetime.timedelta(seconds=1, microseconds=29817)}), ('LinearRegression', {'model': LinearRegression(n_jobs=1, positive=True), 'params': {'fit_intercept': True, 'n_jobs': 1, 'positive': True}, 'mae': 0.8328416830147468, 'time': datetime.timedelta(microseconds=459996)}), ('KernelRidge', {'model': KernelRidge(alpha=10, degree=1, gamma=1, kernel='poly'), 'params': {'alpha': 10, 'degree': 1, 'gamma': 1, 'kernel': 'poly'}, 'mae': 0.8380411369943264, 'time': datetime.timedelta(seconds=19, microseconds=291381)}), ('SGDRegressor', {'model': SGDRegressor(alpha=0.1, learning_rate='adaptive', loss='epsilon_insensitive',\n",
      "             penalty='l1'), 'params': {'alpha': 0.1, 'fit_intercept': True, 'learning_rate': 'adaptive', 'loss': 'epsilon_insensitive', 'penalty': 'l1', 'shuffle': True}, 'mae': 0.8586918913502095, 'time': datetime.timedelta(seconds=16, microseconds=440160)}), ('XGBRegressor', {'model': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...), 'params': {'max_depth': 2, 'n_estimators': 50}, 'mae': 0.8869668014587895, 'time': datetime.timedelta(seconds=52, microseconds=29238)}), ('RandomForestRegressor', {'model': RandomForestRegressor(max_depth=2, n_estimators=200), 'params': {'max_depth': 2, 'n_estimators': 200}, 'mae': 0.8872238509005834, 'time': datetime.timedelta(seconds=101, microseconds=141777)}), ('GradientBoostingRegressor', {'model': GradientBoostingRegressor(max_depth=2, n_estimators=50), 'params': {'max_depth': 2, 'n_estimators': 50}, 'mae': 0.8914451297676815, 'time': datetime.timedelta(seconds=34, microseconds=869591)}), ('AdaBoostRegressor', {'model': AdaBoostRegressor(learning_rate=0.01), 'params': {'learning_rate': 0.01, 'n_estimators': 50}, 'mae': 0.894452064325008, 'time': datetime.timedelta(seconds=39, microseconds=465763)}), ('DecisionTreeRegressor', {'model': DecisionTreeRegressor(max_depth=2), 'params': {'max_depth': 2}, 'mae': 0.9234377434938444, 'time': datetime.timedelta(microseconds=230183)}), ('KNeighborsRegressor', {'model': KNeighborsRegressor(n_neighbors=10), 'params': {'n_neighbors': 10}, 'mae': 0.9758064516129034, 'time': datetime.timedelta(microseconds=179383)}), ('ElasticNet', {'model': ElasticNet(alpha=1, l1_ratio=0.1), 'params': {'alpha': 1, 'fit_intercept': True, 'l1_ratio': 0.1}, 'mae': 1.055773722449682, 'time': datetime.timedelta(microseconds=704456)}), ('Lasso', {'model': Lasso(alpha=1), 'params': {'alpha': 1, 'fit_intercept': True}, 'mae': 1.3304026082028295, 'time': datetime.timedelta(microseconds=178863)})]\n",
      "                                                model  \\\n",
      "0                       Ridge(alpha=1, solver='lsqr')   \n",
      "1           LinearRegression(n_jobs=1, positive=True)   \n",
      "2   KernelRidge(alpha=10, degree=1, gamma=1, kerne...   \n",
      "3   SGDRegressor(alpha=0.1, learning_rate='adaptiv...   \n",
      "4   XGBRegressor(base_score=None, booster=None, ca...   \n",
      "5   (DecisionTreeRegressor(max_depth=2, max_featur...   \n",
      "6   ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
      "7   (DecisionTreeRegressor(max_depth=3, random_sta...   \n",
      "8                  DecisionTreeRegressor(max_depth=2)   \n",
      "9                 KNeighborsRegressor(n_neighbors=10)   \n",
      "10                  ElasticNet(alpha=1, l1_ratio=0.1)   \n",
      "11                                     Lasso(alpha=1)   \n",
      "\n",
      "                                               params       mae  \\\n",
      "0   {'alpha': 1, 'fit_intercept': True, 'solver': ...  0.827189   \n",
      "1   {'fit_intercept': True, 'n_jobs': 1, 'positive...  0.832842   \n",
      "2   {'alpha': 10, 'degree': 1, 'gamma': 1, 'kernel...  0.838041   \n",
      "3   {'alpha': 0.1, 'fit_intercept': True, 'learnin...  0.858692   \n",
      "4                {'max_depth': 2, 'n_estimators': 50}  0.886967   \n",
      "5               {'max_depth': 2, 'n_estimators': 200}  0.887224   \n",
      "6                {'max_depth': 2, 'n_estimators': 50}  0.891445   \n",
      "7         {'learning_rate': 0.01, 'n_estimators': 50}  0.894452   \n",
      "8                                    {'max_depth': 2}  0.923438   \n",
      "9                                 {'n_neighbors': 10}  0.975806   \n",
      "10  {'alpha': 1, 'fit_intercept': True, 'l1_ratio'...  1.055774   \n",
      "11                {'alpha': 1, 'fit_intercept': True}  1.330403   \n",
      "\n",
      "                     time  \n",
      "0  0 days 00:00:01.029817  \n",
      "1  0 days 00:00:00.459996  \n",
      "2  0 days 00:00:19.291381  \n",
      "3  0 days 00:00:16.440160  \n",
      "4  0 days 00:00:52.029238  \n",
      "5  0 days 00:01:41.141777  \n",
      "6  0 days 00:00:34.869591  \n",
      "7  0 days 00:00:39.465763  \n",
      "8  0 days 00:00:00.230183  \n",
      "9  0 days 00:00:00.179383  \n",
      "10 0 days 00:00:00.704456  \n",
      "11 0 days 00:00:00.178863  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge(alpha=1, solver='lsqr')</td>\n",
       "      <td>{'alpha': 1, 'fit_intercept': True, 'solver': ...</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0 days 00:00:01.029817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression(n_jobs=1, positive=True)</td>\n",
       "      <td>{'fit_intercept': True, 'n_jobs': 1, 'positive...</td>\n",
       "      <td>0.832842</td>\n",
       "      <td>0 days 00:00:00.459996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KernelRidge(alpha=10, degree=1, gamma=1, kerne...</td>\n",
       "      <td>{'alpha': 10, 'degree': 1, 'gamma': 1, 'kernel...</td>\n",
       "      <td>0.838041</td>\n",
       "      <td>0 days 00:00:19.291381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGDRegressor(alpha=0.1, learning_rate='adaptiv...</td>\n",
       "      <td>{'alpha': 0.1, 'fit_intercept': True, 'learnin...</td>\n",
       "      <td>0.858692</td>\n",
       "      <td>0 days 00:00:16.440160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, ca...</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 50}</td>\n",
       "      <td>0.886967</td>\n",
       "      <td>0 days 00:00:52.029238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeRegressor(max_depth=2, max_featur...</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 200}</td>\n",
       "      <td>0.887224</td>\n",
       "      <td>0 days 00:01:41.141777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 50}</td>\n",
       "      <td>0.891445</td>\n",
       "      <td>0 days 00:00:34.869591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(DecisionTreeRegressor(max_depth=3, random_sta...</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 50}</td>\n",
       "      <td>0.894452</td>\n",
       "      <td>0 days 00:00:39.465763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTreeRegressor(max_depth=2)</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>0.923438</td>\n",
       "      <td>0 days 00:00:00.230183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsRegressor(n_neighbors=10)</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.975806</td>\n",
       "      <td>0 days 00:00:00.179383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ElasticNet(alpha=1, l1_ratio=0.1)</td>\n",
       "      <td>{'alpha': 1, 'fit_intercept': True, 'l1_ratio'...</td>\n",
       "      <td>1.055774</td>\n",
       "      <td>0 days 00:00:00.704456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>{'alpha': 1, 'fit_intercept': True}</td>\n",
       "      <td>1.330403</td>\n",
       "      <td>0 days 00:00:00.178863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  \\\n",
       "0                       Ridge(alpha=1, solver='lsqr')   \n",
       "1           LinearRegression(n_jobs=1, positive=True)   \n",
       "2   KernelRidge(alpha=10, degree=1, gamma=1, kerne...   \n",
       "3   SGDRegressor(alpha=0.1, learning_rate='adaptiv...   \n",
       "4   XGBRegressor(base_score=None, booster=None, ca...   \n",
       "5   (DecisionTreeRegressor(max_depth=2, max_featur...   \n",
       "6   ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "7   (DecisionTreeRegressor(max_depth=3, random_sta...   \n",
       "8                  DecisionTreeRegressor(max_depth=2)   \n",
       "9                 KNeighborsRegressor(n_neighbors=10)   \n",
       "10                  ElasticNet(alpha=1, l1_ratio=0.1)   \n",
       "11                                     Lasso(alpha=1)   \n",
       "\n",
       "                                               params       mae  \\\n",
       "0   {'alpha': 1, 'fit_intercept': True, 'solver': ...  0.827189   \n",
       "1   {'fit_intercept': True, 'n_jobs': 1, 'positive...  0.832842   \n",
       "2   {'alpha': 10, 'degree': 1, 'gamma': 1, 'kernel...  0.838041   \n",
       "3   {'alpha': 0.1, 'fit_intercept': True, 'learnin...  0.858692   \n",
       "4                {'max_depth': 2, 'n_estimators': 50}  0.886967   \n",
       "5               {'max_depth': 2, 'n_estimators': 200}  0.887224   \n",
       "6                {'max_depth': 2, 'n_estimators': 50}  0.891445   \n",
       "7         {'learning_rate': 0.01, 'n_estimators': 50}  0.894452   \n",
       "8                                    {'max_depth': 2}  0.923438   \n",
       "9                                 {'n_neighbors': 10}  0.975806   \n",
       "10  {'alpha': 1, 'fit_intercept': True, 'l1_ratio'...  1.055774   \n",
       "11                {'alpha': 1, 'fit_intercept': True}  1.330403   \n",
       "\n",
       "                     time  \n",
       "0  0 days 00:00:01.029817  \n",
       "1  0 days 00:00:00.459996  \n",
       "2  0 days 00:00:19.291381  \n",
       "3  0 days 00:00:16.440160  \n",
       "4  0 days 00:00:52.029238  \n",
       "5  0 days 00:01:41.141777  \n",
       "6  0 days 00:00:34.869591  \n",
       "7  0 days 00:00:39.465763  \n",
       "8  0 days 00:00:00.230183  \n",
       "9  0 days 00:00:00.179383  \n",
       "10 0 days 00:00:00.704456  \n",
       "11 0 days 00:00:00.178863  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings_away = {}\n",
    "training_process(rankings_away, features_away, target_away)\n",
    "# train_model(rankings_away, 'LinearRegression', features_away, target_away)\n",
    "# train_model(rankings_away, 'AdaBoostRegressor', features_away, target_away)\n",
    "# train_model(rankings_away, 'RandomForestRegressor', features_away, target_away)\n",
    "# train_model(rankings_away, 'XGBRegressor', features_away, target_away)\n",
    "# train_model(rankings_away, 'DecisionTreeRegressor', features_away, target_away)\n",
    "# train_model(rankings_away, 'KNeighborsRegressor', features_away, target_away)\n",
    "# train_model(rankings_away, 'GradientBoostingRegressor', features_away, target_away)\n",
    "# train_model(rankings_away, 'Ridge', features_away, target_away)\n",
    "# train_model(rankings_away, 'Lasso', features_away, target_away)\n",
    "# train_model(rankings_away, 'ElasticNet', features_away, target_away)\n",
    "# train_model(rankings_away, 'SGDRegressor', features_away, target_away)\n",
    "# train_model(rankings_away, 'KernelRidge', features_away, target_away)\n",
    "\n",
    "print(sorted(rankings_away.items(), key=lambda x: x[1]['mae']))\n",
    "\n",
    "# Save models and their info\n",
    "save_best_model('away',rankings_away)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models from Pickle file\n",
    "\n",
    "Load the models from the pickle to a REST API. I'm going to use _fastapi_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- PREDICTIONS ----\n",
    "\n",
    "cols: list[str] = ['Wk', 'Numeric_Day', 'Numeric_Home', 'Numeric_Away', 'Numeric_Time',\n",
    "       'xGHome_xGAway_1', 'xGHome_xGAway_2', 'xGHome_xGAway_3']\n",
    "# display(features_away[cols].sample(1))\n",
    "\n",
    "# Pick random number between 0 and len(data)\n",
    "random_index = np.random.randint(0, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predicting ... 3 : 0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display(features_away[cols][random_index:random_index+1], features_home[cols][random_index:random_index+1])\n",
    "# Predict home score for match at random index\n",
    "predict_res(features_home[cols][random_index:random_index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predicting ... 3 : 0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_res(features_away[cols][random_index:random_index+1])\n",
    "\n",
    "# The prediction is the same for both because the features are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Streamlit to transform the data, load the model and do a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL Process and Data Integration\n",
    "\n",
    "__Apache Airflow__ supports a few databases: \n",
    "- SQLite _Lightweight filebased database suitable for small-scale deployments and testing_\n",
    "- PostgreSQL _Relational database widely used in production environments_\n",
    "- MySQL _Popular relational database widely used_\n",
    "- Microsoft SQL Server _Commercial relational database widely used in enterprises_\n",
    "- Oracle _Commercial relational database widely used in enterprises_\n",
    "- Amazon RedShift _Cloud-based data warehouse optimized for analytics workloads_\n",
    "- Google BigQuery _Cloud-based data warehouse optimized for analytics workloads_\n",
    "- Apache Casssandra _Distributed No-SQL database optimized for high scalability and availability_\n",
    "- Apache Hive _Data warehouse infrastructure for data summarization, querying and analytics_\n",
    "\n",
    "I'm using SQLite because it's a small scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load task\n",
    "def load_data(matches):\n",
    "    # Connect to database\n",
    "    conn = sqlite3.connect('assets/spanish_matches.db')\n",
    "\n",
    "    # Create cursor\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create table\n",
    "    c.execute(\"\"\"CREATE TABLE IF NOT EXISTS matches (\n",
    "        Wk INTERGER,\n",
    "        Day TEXT,\n",
    "        Date DATE,\n",
    "        Time TIME,\n",
    "        Home TEXT,\n",
    "        xGHome FLOAT,\n",
    "        Score TEXT,\n",
    "        xGAway FLOAT,\n",
    "        Away TEXT,\n",
    "        xPHome FLOAT,\n",
    "        xPAway FLOAT,\n",
    "        ScoreHome INTERGER,\n",
    "        ScoreAway INTERGER,\n",
    "        GoalDifference INTERGER,\n",
    "        Result TEXT,\n",
    "        ExpectedGoalDifference FLOAT,\n",
    "        Points INTERGER,\n",
    "        ExpectedPoints INTERGER,\n",
    "        WinPercentage FLOAT,\n",
    "        TotalGoals INTERGER,\n",
    "        xGRatio FLOAT\n",
    "    )\"\"\")\n",
    "\n",
    "    # Insert DataFrame records one by one.\n",
    "    for i, row in matches.iterrows():\n",
    "        c.execute(\"\"\"INSERT INTO matches VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\"\"\", (\n",
    "            row['Wk'],\n",
    "            row['Day'],\n",
    "            row['Date'],\n",
    "            row['Time'],\n",
    "            row['Home'],\n",
    "            row['xGHome'],\n",
    "            row['Score'],\n",
    "            row['xGAway'],\n",
    "            row['Away'],\n",
    "            row['xPHome'],\n",
    "            row['xPAway'],\n",
    "            row['ScoreHome'],\n",
    "            row['ScoreAway'],\n",
    "            row['GoalDifference'],\n",
    "            row['Result'],\n",
    "            row['ExpectedGoalDifference'],\n",
    "            row['Points'],\n",
    "            row['ExpectedPoints'],\n",
    "            row['WinPercentage'],\n",
    "            row['TotalGoals'],\n",
    "            row['xGRatio']\n",
    "        ))\n",
    "\n",
    "    # Commit changes\n",
    "    conn.commit()\n",
    "\n",
    "    # Close cursor and connection\n",
    "    c.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign tasks\n",
    "extract_task = PythonOperator(\n",
    "    task_id='extract_data',\n",
    "    python_callable=extract_data,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "transform_task = PythonOperator(\n",
    "    task_id='transform_data',\n",
    "    python_callable=transform_data,\n",
    "    op_kwargs={'matches': '{{ ti.xcom_pull(task_ids=\"extract_data\") }}'},\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "load_task = PythonOperator(\n",
    "    task_id='load_data',\n",
    "    python_callable=load_data,\n",
    "    op_kwargs={'matches': '{{ ti.xcom_pull(task_ids=\"transform_data\") }}'},\n",
    "    dag=dag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/airflow_env/bin/airflow scheduler -D\n",
    "!~/airflow_env/bin/airflow webserver -D\n",
    "\n",
    "!~/airflow_env/bin/airflow dags list\n",
    "\n",
    "!~/airflow_env/bin/airflow cheat-sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Quality Assurance\n",
    "\n",
    "To validate the quality of the data, I'm connecting to the database to check for null values in each column of the matches table.  \n",
    "Specifically, I'll check the data type, the range anf completeness of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data in the database and ensure the proper quality\n",
    "def validate_data():\n",
    "    # Connect to database\n",
    "    conn = sqlite3.connect('assets/spanish_matches.db')\n",
    "\n",
    "    # Create cursor\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Data type validation\n",
    "    c.execute(\"\"\"SELECT COUNT(*) FROM matches where CAST(Wk AS INTEGER) IS NULL\"\"\")\n",
    "    null_count = c.fetchone()[0]\n",
    "    if null_count == 0:\n",
    "        print('Data type validation passed.')\n",
    "    else:\n",
    "        print(f'Data type validation failed with {null_count} null values.')\n",
    "\n",
    "    # Data range validation\n",
    "    c.execute(\"\"\"SELECT COUNT(*) FROM matches where Wk < 1 OR Wk > 10\"\"\")\n",
    "    range_count = c.fetchone()[0]\n",
    "    if range_count == 0:\n",
    "        print('Data range validation passed.')\n",
    "    else:\n",
    "        print(f'Data range validation failed with {range_count} values out of range.')\n",
    "\n",
    "    # Data completeness validation\n",
    "    c.execute(\"\"\"SELECT COUNT(*) FROM matches where Wk IS NULL\"\"\")\n",
    "    completeness_count = c.fetchone()[0]\n",
    "    if completeness_count == 0:\n",
    "        print('Data completeness validation passed.')\n",
    "    else:\n",
    "        print(f'Data completeness validation failed with {completeness_count} null values.')\n",
    "\n",
    "    c.close()\n",
    "    conn.close()\n",
    "\n",
    "validate_task = PythonOperator(\n",
    "    task_id='validate_data',\n",
    "    python_callable=validate_data,\n",
    "    op_kwargs={'matches': '{{ ti.xcom_pull(task_ids=\"load_data\") }}'},\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "# Define task dependencies\n",
    "extract_task >> transform_task >> load_task >> validate_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting and Analysis\n",
    "\n",
    "Generate meaningful insights and reports.\n",
    "- Trend analysis\n",
    "- Team Performance analysis\n",
    "- Team comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend analysis\n",
    "def trend_analysis():\n",
    "    # Connect to database\n",
    "    conn = sqlite3.connect('assets/spanish_matches.db')\n",
    "\n",
    "    # Create cursor\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Data type validation\n",
    "    c.execute(\"\"\"SELECT * FROM matches\"\"\")\n",
    "    matches = pd.DataFrame(c.fetchall())\n",
    "    \n",
    "    # Define plot function\n",
    "    def plot_data():\n",
    "        sns.lineplot(x='Date', y='TotlaGoals', data=matches)\n",
    "        plt.title('Total Goals Scored')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Total Goals')\n",
    "        plt.show()\n",
    "    # Look at the correlation between the expected goals and the actual goals\n",
    "    def calculate_correlation():\n",
    "        corr_home = matches['xGHome'].corr(matches['ScoreHome'])\n",
    "        print(f'Correlation between expected Goals for the Home and actual goals Home: {corr_home}')\n",
    "        corr_away = matches['xGAway'].corr(matches['ScoreAway'])\n",
    "        print(f'Correlation between expected Goals for the Away and actual goals Away: {corr_away}')\n",
    "    \n",
    "    plot_data()\n",
    "    calculate_correlation()\n",
    "\n",
    "trend_analysis_task = PythonOperator(\n",
    "    task_id='trend_analysis',\n",
    "    python_callable=trend_analysis,\n",
    "    op_kwargs={'matches': '{{ ti.xcom_pull(task_ids=\"validate_data\") }}'},\n",
    "    dag=dag\n",
    ")   \n",
    "\n",
    "# Define task dependencies\n",
    "extract_task >> transform_task >> load_task >> validate_task >> trend_analysis_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exectute the DAG workflow and view the results in the Airflow UI from scripts/DataPipelining.py\n",
    "!~/airflow_env/bin/airflow trigger_dag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert notebook to python script\n",
    "!jupyter nbconvert --to script DataPipelining.ipynb --output-dir='airflow/dags/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
